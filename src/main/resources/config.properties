spark.master=yarn
spark.deploy.mode=cluster
spark.home=/data/cloudera/parcels/SPARK2/lib/spark2
spark.yarn.jars=hdfs://127.0.0.1:8020/user/spark/share/lib/*.jar

yarn.url=http://127.0.0.1:8088/ws/v1/cluster/apps/

yarn.resourcemanager.hostname=127.0.0.1
yarn.resourcemanager.address=127.0.0.1:8032
yarn.access.namenode=hdfs://127.0.0.1:9000
yarn.stagingDir=hdfs://127.0.0.1:9000/tmp/

hive.metastore.uris=thrift://127.0.0.1:9083

#Hdfs path, these paths will be created autometicly
checkpoint.path=hdfs://127.0.0.1:9000/user/piflow/checkpoints/
debug.path=hdfs://127.0.0.1:9000/user/piflow/debug/
increment.path=hdfs://127.0.0.1:9000/user/piflow/increment/

#show data in log, set 0 if you do not show the logs
data.show=10

#monitor the throughput of flow
monitor.throughput=true

